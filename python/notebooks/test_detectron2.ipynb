{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from detectron2.layers import Conv2d\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.modeling import build_model\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_conv_and_bn(conv):\n",
    "    # Fuse convolution and batchnorm layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n",
    "    bn = conv.norm\n",
    "    # init\n",
    "    fusedconv = nn.Conv2d(conv.in_channels,\n",
    "                          conv.out_channels,\n",
    "                          kernel_size=conv.kernel_size,\n",
    "                          stride=conv.stride,\n",
    "                          padding=conv.padding,\n",
    "                          groups=conv.groups,\n",
    "                          bias=True).requires_grad_(False).to(conv.weight.device)\n",
    "\n",
    "    # prepare filters\n",
    "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
    "    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps + bn.running_var)))\n",
    "    fusedconv.weight.copy_(torch.mm(w_bn, w_conv).view(fusedconv.weight.size()))\n",
    "\n",
    "    # prepare spatial bias\n",
    "    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n",
    "    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
    "    fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)\n",
    "\n",
    "    return fusedconv\n",
    "\n",
    "def fuse_bn(model):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, Conv2d) and child.norm is not None:\n",
    "            setattr(model, child_name, fuse_conv_and_bn(child))\n",
    "        else:\n",
    "            fuse_bn(child)\n",
    "\n",
    "def gen_wts(model, filename):\n",
    "    f = open('./' + filename + '.wts', 'w')\n",
    "    f.write('{}\\n'.format(len(model.state_dict().keys())))\n",
    "    for k, v in model.state_dict().items():\n",
    "        vr = v.reshape(-1).cpu().numpy()\n",
    "        print('{}\\t{}\\t{}'.format(k, v.shape, len(vr)))\n",
    "        f.write('{} {} '.format(k, len(vr)))\n",
    "        for vv in vr:\n",
    "            f.write(' ')\n",
    "            f.write(struct.pack('>f',float(vv)).hex())\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'F:/models/detectron2/COCO-Detection/faster_rcnn_R_50_C4_1x.pkl'\n",
    "config_path = 'F:/models/detectron2/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redirection(config):\n",
    "    d = 'E:/works/timesai_tools/timesAI_platform/times-ai/visionCode/algorithm_contribute/py_module/timesai_det1_interfance/configs/COCO-Detection'\n",
    "    fname = os.path.basename(config)\n",
    "    return os.path.join(d, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.merge_from_file(redirection(config_path))\n",
    "cfg.MODEL.WEIGHTS = model_path\n",
    "cfg.freeze()\n",
    "model = build_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.stem.conv1.weight\ttorch.Size([64, 3, 7, 7])\t9408\n",
      "backbone.stem.conv1.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.0.shortcut.weight\ttorch.Size([256, 64, 1, 1])\t16384\n",
      "backbone.res2.0.shortcut.bias\ttorch.Size([256])\t256\n",
      "backbone.res2.0.conv1.weight\ttorch.Size([64, 64, 1, 1])\t4096\n",
      "backbone.res2.0.conv1.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.0.conv2.weight\ttorch.Size([64, 64, 3, 3])\t36864\n",
      "backbone.res2.0.conv2.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.0.conv3.weight\ttorch.Size([256, 64, 1, 1])\t16384\n",
      "backbone.res2.0.conv3.bias\ttorch.Size([256])\t256\n",
      "backbone.res2.1.conv1.weight\ttorch.Size([64, 256, 1, 1])\t16384\n",
      "backbone.res2.1.conv1.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.1.conv2.weight\ttorch.Size([64, 64, 3, 3])\t36864\n",
      "backbone.res2.1.conv2.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.1.conv3.weight\ttorch.Size([256, 64, 1, 1])\t16384\n",
      "backbone.res2.1.conv3.bias\ttorch.Size([256])\t256\n",
      "backbone.res2.2.conv1.weight\ttorch.Size([64, 256, 1, 1])\t16384\n",
      "backbone.res2.2.conv1.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.2.conv2.weight\ttorch.Size([64, 64, 3, 3])\t36864\n",
      "backbone.res2.2.conv2.bias\ttorch.Size([64])\t64\n",
      "backbone.res2.2.conv3.weight\ttorch.Size([256, 64, 1, 1])\t16384\n",
      "backbone.res2.2.conv3.bias\ttorch.Size([256])\t256\n",
      "backbone.res3.0.shortcut.weight\ttorch.Size([512, 256, 1, 1])\t131072\n",
      "backbone.res3.0.shortcut.bias\ttorch.Size([512])\t512\n",
      "backbone.res3.0.conv1.weight\ttorch.Size([128, 256, 1, 1])\t32768\n",
      "backbone.res3.0.conv1.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.0.conv2.weight\ttorch.Size([128, 128, 3, 3])\t147456\n",
      "backbone.res3.0.conv2.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.0.conv3.weight\ttorch.Size([512, 128, 1, 1])\t65536\n",
      "backbone.res3.0.conv3.bias\ttorch.Size([512])\t512\n",
      "backbone.res3.1.conv1.weight\ttorch.Size([128, 512, 1, 1])\t65536\n",
      "backbone.res3.1.conv1.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.1.conv2.weight\ttorch.Size([128, 128, 3, 3])\t147456\n",
      "backbone.res3.1.conv2.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.1.conv3.weight\ttorch.Size([512, 128, 1, 1])\t65536\n",
      "backbone.res3.1.conv3.bias\ttorch.Size([512])\t512\n",
      "backbone.res3.2.conv1.weight\ttorch.Size([128, 512, 1, 1])\t65536\n",
      "backbone.res3.2.conv1.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.2.conv2.weight\ttorch.Size([128, 128, 3, 3])\t147456\n",
      "backbone.res3.2.conv2.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.2.conv3.weight\ttorch.Size([512, 128, 1, 1])\t65536\n",
      "backbone.res3.2.conv3.bias\ttorch.Size([512])\t512\n",
      "backbone.res3.3.conv1.weight\ttorch.Size([128, 512, 1, 1])\t65536\n",
      "backbone.res3.3.conv1.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.3.conv2.weight\ttorch.Size([128, 128, 3, 3])\t147456\n",
      "backbone.res3.3.conv2.bias\ttorch.Size([128])\t128\n",
      "backbone.res3.3.conv3.weight\ttorch.Size([512, 128, 1, 1])\t65536\n",
      "backbone.res3.3.conv3.bias\ttorch.Size([512])\t512\n",
      "backbone.res4.0.shortcut.weight\ttorch.Size([1024, 512, 1, 1])\t524288\n",
      "backbone.res4.0.shortcut.bias\ttorch.Size([1024])\t1024\n",
      "backbone.res4.0.conv1.weight\ttorch.Size([256, 512, 1, 1])\t131072\n",
      "backbone.res4.0.conv1.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.0.conv2.weight\ttorch.Size([256, 256, 3, 3])\t589824\n",
      "backbone.res4.0.conv2.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.0.conv3.weight\ttorch.Size([1024, 256, 1, 1])\t262144\n",
      "backbone.res4.0.conv3.bias\ttorch.Size([1024])\t1024\n",
      "backbone.res4.1.conv1.weight\ttorch.Size([256, 1024, 1, 1])\t262144\n",
      "backbone.res4.1.conv1.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.1.conv2.weight\ttorch.Size([256, 256, 3, 3])\t589824\n",
      "backbone.res4.1.conv2.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.1.conv3.weight\ttorch.Size([1024, 256, 1, 1])\t262144\n",
      "backbone.res4.1.conv3.bias\ttorch.Size([1024])\t1024\n",
      "backbone.res4.2.conv1.weight\ttorch.Size([256, 1024, 1, 1])\t262144\n",
      "backbone.res4.2.conv1.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.2.conv2.weight\ttorch.Size([256, 256, 3, 3])\t589824\n",
      "backbone.res4.2.conv2.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.2.conv3.weight\ttorch.Size([1024, 256, 1, 1])\t262144\n",
      "backbone.res4.2.conv3.bias\ttorch.Size([1024])\t1024\n",
      "backbone.res4.3.conv1.weight\ttorch.Size([256, 1024, 1, 1])\t262144\n",
      "backbone.res4.3.conv1.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.3.conv2.weight\ttorch.Size([256, 256, 3, 3])\t589824\n",
      "backbone.res4.3.conv2.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.3.conv3.weight\ttorch.Size([1024, 256, 1, 1])\t262144\n",
      "backbone.res4.3.conv3.bias\ttorch.Size([1024])\t1024\n",
      "backbone.res4.4.conv1.weight\ttorch.Size([256, 1024, 1, 1])\t262144\n",
      "backbone.res4.4.conv1.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.4.conv2.weight\ttorch.Size([256, 256, 3, 3])\t589824\n",
      "backbone.res4.4.conv2.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.4.conv3.weight\ttorch.Size([1024, 256, 1, 1])\t262144\n",
      "backbone.res4.4.conv3.bias\ttorch.Size([1024])\t1024\n",
      "backbone.res4.5.conv1.weight\ttorch.Size([256, 1024, 1, 1])\t262144\n",
      "backbone.res4.5.conv1.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.5.conv2.weight\ttorch.Size([256, 256, 3, 3])\t589824\n",
      "backbone.res4.5.conv2.bias\ttorch.Size([256])\t256\n",
      "backbone.res4.5.conv3.weight\ttorch.Size([1024, 256, 1, 1])\t262144\n",
      "backbone.res4.5.conv3.bias\ttorch.Size([1024])\t1024\n",
      "proposal_generator.rpn_head.conv.weight\ttorch.Size([1024, 1024, 3, 3])\t9437184\n",
      "proposal_generator.rpn_head.conv.bias\ttorch.Size([1024])\t1024\n",
      "proposal_generator.rpn_head.objectness_logits.weight\ttorch.Size([15, 1024, 1, 1])\t15360\n",
      "proposal_generator.rpn_head.objectness_logits.bias\ttorch.Size([15])\t15\n",
      "proposal_generator.rpn_head.anchor_deltas.weight\ttorch.Size([60, 1024, 1, 1])\t61440\n",
      "proposal_generator.rpn_head.anchor_deltas.bias\ttorch.Size([60])\t60\n",
      "roi_heads.res5.0.shortcut.weight\ttorch.Size([2048, 1024, 1, 1])\t2097152\n",
      "roi_heads.res5.0.shortcut.bias\ttorch.Size([2048])\t2048\n",
      "roi_heads.res5.0.conv1.weight\ttorch.Size([512, 1024, 1, 1])\t524288\n",
      "roi_heads.res5.0.conv1.bias\ttorch.Size([512])\t512\n",
      "roi_heads.res5.0.conv2.weight\ttorch.Size([512, 512, 3, 3])\t2359296\n",
      "roi_heads.res5.0.conv2.bias\ttorch.Size([512])\t512\n",
      "roi_heads.res5.0.conv3.weight\ttorch.Size([2048, 512, 1, 1])\t1048576\n",
      "roi_heads.res5.0.conv3.bias\ttorch.Size([2048])\t2048\n",
      "roi_heads.res5.1.conv1.weight\ttorch.Size([512, 2048, 1, 1])\t1048576\n",
      "roi_heads.res5.1.conv1.bias\ttorch.Size([512])\t512\n",
      "roi_heads.res5.1.conv2.weight\ttorch.Size([512, 512, 3, 3])\t2359296\n",
      "roi_heads.res5.1.conv2.bias\ttorch.Size([512])\t512\n",
      "roi_heads.res5.1.conv3.weight\ttorch.Size([2048, 512, 1, 1])\t1048576\n",
      "roi_heads.res5.1.conv3.bias\ttorch.Size([2048])\t2048\n",
      "roi_heads.res5.2.conv1.weight\ttorch.Size([512, 2048, 1, 1])\t1048576\n",
      "roi_heads.res5.2.conv1.bias\ttorch.Size([512])\t512\n",
      "roi_heads.res5.2.conv2.weight\ttorch.Size([512, 512, 3, 3])\t2359296\n",
      "roi_heads.res5.2.conv2.bias\ttorch.Size([512])\t512\n",
      "roi_heads.res5.2.conv3.weight\ttorch.Size([2048, 512, 1, 1])\t1048576\n",
      "roi_heads.res5.2.conv3.bias\ttorch.Size([2048])\t2048\n",
      "roi_heads.box_predictor.cls_score.weight\ttorch.Size([81, 2048])\t165888\n",
      "roi_heads.box_predictor.cls_score.bias\ttorch.Size([81])\t81\n",
      "roi_heads.box_predictor.bbox_pred.weight\ttorch.Size([320, 2048])\t655360\n",
      "roi_heads.box_predictor.bbox_pred.bias\ttorch.Size([320])\t320\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "fuse_bn(model)\n",
    "gen_wts(model, 'faster')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
